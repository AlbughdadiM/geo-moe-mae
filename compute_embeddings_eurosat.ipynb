{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d4dcd98",
   "metadata": {},
   "source": [
    "# ==============================================================\n",
    "# Compute Embeddings of the EuroSAT-LS Dataset Using Pretrained MOE-MAE Encoder Weights\n",
    "# =============================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f55baed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from models.moe_mae import MOEMAE, build_model\n",
    "from datasets.eurosat import EuroSATDatasetLS\n",
    "from transformation.transformer import ToFloat, ZScoreNormalize\n",
    "from utils.data_config import BigEarthNetInfo\n",
    "from embed.compute_embed import compute_geomoemae_embeddings\n",
    "from utils.data_utils import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "516932a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_txt_train = \"/mnt/storage/data/eurosat-l/eurosat-train.txt\"\n",
    "data_txt_val = \"/mnt/storage/data/eurosat-l/eurosat-val.txt\"\n",
    "data_txt_test = \"/mnt/storage/data/eurosat-l/eurosat-test.txt\"\n",
    "data_path = \"/mnt/storage/data/eurosat-l/eurosat-l\"\n",
    "save_path = \"/mnt/storage/data/eurosat-l\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec10ffe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "        \"cuda\"\n",
    "        if torch.cuda.is_available()\n",
    "        else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "    )\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d0cd99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cloud-user/code/lightweight-foundation-models/utils/data_utils.py:29: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, map_location=device)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "mLiT(\n",
       "  (patch_proj): Conv2d(7, 144, kernel_size=(4, 4), stride=(4, 4))\n",
       "  (week_proj): Linear(in_features=2, out_features=144, bias=True)\n",
       "  (hour_proj): Linear(in_features=2, out_features=144, bias=True)\n",
       "  (lat_proj): Linear(in_features=2, out_features=144, bias=True)\n",
       "  (lon_proj): Linear(in_features=2, out_features=144, bias=True)\n",
       "  (layers): ModuleList(\n",
       "    (0): MoETransformerEncoderLayer(\n",
       "      (norm1): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GroupedQueryAttention(\n",
       "        (q_proj): Linear(in_features=144, out_features=144, bias=True)\n",
       "        (k_proj): Linear(in_features=144, out_features=72, bias=True)\n",
       "        (v_proj): Linear(in_features=144, out_features=72, bias=True)\n",
       "        (out_proj): Linear(in_features=144, out_features=144, bias=True)\n",
       "        (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (proj_dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (norm2): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
       "      (moe): MoELayer(\n",
       "        (experts): ModuleList(\n",
       "          (0-2): 3 x SwiGLU(\n",
       "            (W): Linear(in_features=144, out_features=144, bias=True)\n",
       "            (V): Linear(in_features=144, out_features=144, bias=True)\n",
       "            (W2): Linear(in_features=144, out_features=144, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (gate): NoisyTopKGate(\n",
       "          (Wg): Linear(in_features=144, out_features=3, bias=True)\n",
       "          (Wnoise): Linear(in_features=144, out_features=3, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): MoETransformerEncoderLayer(\n",
       "      (norm1): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GroupedQueryAttention(\n",
       "        (q_proj): Linear(in_features=144, out_features=144, bias=True)\n",
       "        (k_proj): Linear(in_features=144, out_features=72, bias=True)\n",
       "        (v_proj): Linear(in_features=144, out_features=72, bias=True)\n",
       "        (out_proj): Linear(in_features=144, out_features=144, bias=True)\n",
       "        (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (proj_dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (norm2): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
       "      (moe): MoELayer(\n",
       "        (experts): ModuleList(\n",
       "          (0-2): 3 x SwiGLU(\n",
       "            (W): Linear(in_features=144, out_features=138, bias=True)\n",
       "            (V): Linear(in_features=144, out_features=138, bias=True)\n",
       "            (W2): Linear(in_features=138, out_features=144, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (gate): NoisyTopKGate(\n",
       "          (Wg): Linear(in_features=144, out_features=3, bias=True)\n",
       "          (Wnoise): Linear(in_features=144, out_features=3, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): MoETransformerEncoderLayer(\n",
       "      (norm1): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GroupedQueryAttention(\n",
       "        (q_proj): Linear(in_features=144, out_features=144, bias=True)\n",
       "        (k_proj): Linear(in_features=144, out_features=72, bias=True)\n",
       "        (v_proj): Linear(in_features=144, out_features=72, bias=True)\n",
       "        (out_proj): Linear(in_features=144, out_features=144, bias=True)\n",
       "        (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (proj_dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (norm2): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
       "      (moe): MoELayer(\n",
       "        (experts): ModuleList(\n",
       "          (0-2): 3 x SwiGLU(\n",
       "            (W): Linear(in_features=144, out_features=133, bias=True)\n",
       "            (V): Linear(in_features=144, out_features=133, bias=True)\n",
       "            (W2): Linear(in_features=133, out_features=144, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (gate): NoisyTopKGate(\n",
       "          (Wg): Linear(in_features=144, out_features=3, bias=True)\n",
       "          (Wnoise): Linear(in_features=144, out_features=3, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): MoETransformerEncoderLayer(\n",
       "      (norm1): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GroupedQueryAttention(\n",
       "        (q_proj): Linear(in_features=144, out_features=144, bias=True)\n",
       "        (k_proj): Linear(in_features=144, out_features=72, bias=True)\n",
       "        (v_proj): Linear(in_features=144, out_features=72, bias=True)\n",
       "        (out_proj): Linear(in_features=144, out_features=144, bias=True)\n",
       "        (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (proj_dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (norm2): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
       "      (moe): MoELayer(\n",
       "        (experts): ModuleList(\n",
       "          (0-2): 3 x SwiGLU(\n",
       "            (W): Linear(in_features=144, out_features=128, bias=True)\n",
       "            (V): Linear(in_features=144, out_features=128, bias=True)\n",
       "            (W2): Linear(in_features=128, out_features=144, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (gate): NoisyTopKGate(\n",
       "          (Wg): Linear(in_features=144, out_features=3, bias=True)\n",
       "          (Wnoise): Linear(in_features=144, out_features=3, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): MoETransformerEncoderLayer(\n",
       "      (norm1): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GroupedQueryAttention(\n",
       "        (q_proj): Linear(in_features=144, out_features=144, bias=True)\n",
       "        (k_proj): Linear(in_features=144, out_features=72, bias=True)\n",
       "        (v_proj): Linear(in_features=144, out_features=72, bias=True)\n",
       "        (out_proj): Linear(in_features=144, out_features=144, bias=True)\n",
       "        (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (proj_dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (norm2): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
       "      (moe): MoELayer(\n",
       "        (experts): ModuleList(\n",
       "          (0-2): 3 x SwiGLU(\n",
       "            (W): Linear(in_features=144, out_features=123, bias=True)\n",
       "            (V): Linear(in_features=144, out_features=123, bias=True)\n",
       "            (W2): Linear(in_features=123, out_features=144, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (gate): NoisyTopKGate(\n",
       "          (Wg): Linear(in_features=144, out_features=3, bias=True)\n",
       "          (Wnoise): Linear(in_features=144, out_features=3, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): MoETransformerEncoderLayer(\n",
       "      (norm1): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GroupedQueryAttention(\n",
       "        (q_proj): Linear(in_features=144, out_features=144, bias=True)\n",
       "        (k_proj): Linear(in_features=144, out_features=72, bias=True)\n",
       "        (v_proj): Linear(in_features=144, out_features=72, bias=True)\n",
       "        (out_proj): Linear(in_features=144, out_features=144, bias=True)\n",
       "        (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (proj_dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (norm2): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
       "      (moe): MoELayer(\n",
       "        (experts): ModuleList(\n",
       "          (0-3): 4 x SwiGLU(\n",
       "            (W): Linear(in_features=144, out_features=118, bias=True)\n",
       "            (V): Linear(in_features=144, out_features=118, bias=True)\n",
       "            (W2): Linear(in_features=118, out_features=144, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (gate): NoisyTopKGate(\n",
       "          (Wg): Linear(in_features=144, out_features=4, bias=True)\n",
       "          (Wnoise): Linear(in_features=144, out_features=4, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (6): MoETransformerEncoderLayer(\n",
       "      (norm1): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GroupedQueryAttention(\n",
       "        (q_proj): Linear(in_features=144, out_features=144, bias=True)\n",
       "        (k_proj): Linear(in_features=144, out_features=72, bias=True)\n",
       "        (v_proj): Linear(in_features=144, out_features=72, bias=True)\n",
       "        (out_proj): Linear(in_features=144, out_features=144, bias=True)\n",
       "        (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (proj_dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (norm2): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
       "      (moe): MoELayer(\n",
       "        (experts): ModuleList(\n",
       "          (0-3): 4 x SwiGLU(\n",
       "            (W): Linear(in_features=144, out_features=113, bias=True)\n",
       "            (V): Linear(in_features=144, out_features=113, bias=True)\n",
       "            (W2): Linear(in_features=113, out_features=144, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (gate): NoisyTopKGate(\n",
       "          (Wg): Linear(in_features=144, out_features=4, bias=True)\n",
       "          (Wnoise): Linear(in_features=144, out_features=4, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (7): MoETransformerEncoderLayer(\n",
       "      (norm1): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GroupedQueryAttention(\n",
       "        (q_proj): Linear(in_features=144, out_features=144, bias=True)\n",
       "        (k_proj): Linear(in_features=144, out_features=72, bias=True)\n",
       "        (v_proj): Linear(in_features=144, out_features=72, bias=True)\n",
       "        (out_proj): Linear(in_features=144, out_features=144, bias=True)\n",
       "        (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (proj_dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (norm2): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
       "      (moe): MoELayer(\n",
       "        (experts): ModuleList(\n",
       "          (0-3): 4 x SwiGLU(\n",
       "            (W): Linear(in_features=144, out_features=108, bias=True)\n",
       "            (V): Linear(in_features=144, out_features=108, bias=True)\n",
       "            (W2): Linear(in_features=108, out_features=144, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (gate): NoisyTopKGate(\n",
       "          (Wg): Linear(in_features=144, out_features=4, bias=True)\n",
       "          (Wnoise): Linear(in_features=144, out_features=4, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (8): MoETransformerEncoderLayer(\n",
       "      (norm1): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GroupedQueryAttention(\n",
       "        (q_proj): Linear(in_features=144, out_features=144, bias=True)\n",
       "        (k_proj): Linear(in_features=144, out_features=72, bias=True)\n",
       "        (v_proj): Linear(in_features=144, out_features=72, bias=True)\n",
       "        (out_proj): Linear(in_features=144, out_features=144, bias=True)\n",
       "        (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (proj_dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (norm2): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
       "      (moe): MoELayer(\n",
       "        (experts): ModuleList(\n",
       "          (0-3): 4 x SwiGLU(\n",
       "            (W): Linear(in_features=144, out_features=102, bias=True)\n",
       "            (V): Linear(in_features=144, out_features=102, bias=True)\n",
       "            (W2): Linear(in_features=102, out_features=144, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (gate): NoisyTopKGate(\n",
       "          (Wg): Linear(in_features=144, out_features=4, bias=True)\n",
       "          (Wnoise): Linear(in_features=144, out_features=4, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (9): MoETransformerEncoderLayer(\n",
       "      (norm1): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GroupedQueryAttention(\n",
       "        (q_proj): Linear(in_features=144, out_features=144, bias=True)\n",
       "        (k_proj): Linear(in_features=144, out_features=72, bias=True)\n",
       "        (v_proj): Linear(in_features=144, out_features=72, bias=True)\n",
       "        (out_proj): Linear(in_features=144, out_features=144, bias=True)\n",
       "        (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (proj_dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (norm2): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
       "      (moe): MoELayer(\n",
       "        (experts): ModuleList(\n",
       "          (0-3): 4 x SwiGLU(\n",
       "            (W): Linear(in_features=144, out_features=97, bias=True)\n",
       "            (V): Linear(in_features=144, out_features=97, bias=True)\n",
       "            (W2): Linear(in_features=97, out_features=144, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (gate): NoisyTopKGate(\n",
       "          (Wg): Linear(in_features=144, out_features=4, bias=True)\n",
       "          (Wnoise): Linear(in_features=144, out_features=4, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (10): MoETransformerEncoderLayer(\n",
       "      (norm1): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GroupedQueryAttention(\n",
       "        (q_proj): Linear(in_features=144, out_features=144, bias=True)\n",
       "        (k_proj): Linear(in_features=144, out_features=72, bias=True)\n",
       "        (v_proj): Linear(in_features=144, out_features=72, bias=True)\n",
       "        (out_proj): Linear(in_features=144, out_features=144, bias=True)\n",
       "        (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (proj_dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (norm2): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
       "      (moe): MoELayer(\n",
       "        (experts): ModuleList(\n",
       "          (0-4): 5 x SwiGLU(\n",
       "            (W): Linear(in_features=144, out_features=92, bias=True)\n",
       "            (V): Linear(in_features=144, out_features=92, bias=True)\n",
       "            (W2): Linear(in_features=92, out_features=144, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (gate): NoisyTopKGate(\n",
       "          (Wg): Linear(in_features=144, out_features=5, bias=True)\n",
       "          (Wnoise): Linear(in_features=144, out_features=5, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (11): MoETransformerEncoderLayer(\n",
       "      (norm1): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GroupedQueryAttention(\n",
       "        (q_proj): Linear(in_features=144, out_features=144, bias=True)\n",
       "        (k_proj): Linear(in_features=144, out_features=72, bias=True)\n",
       "        (v_proj): Linear(in_features=144, out_features=72, bias=True)\n",
       "        (out_proj): Linear(in_features=144, out_features=144, bias=True)\n",
       "        (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (proj_dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (norm2): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
       "      (moe): MoELayer(\n",
       "        (experts): ModuleList(\n",
       "          (0-4): 5 x SwiGLU(\n",
       "            (W): Linear(in_features=144, out_features=87, bias=True)\n",
       "            (V): Linear(in_features=144, out_features=87, bias=True)\n",
       "            (W2): Linear(in_features=87, out_features=144, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (gate): NoisyTopKGate(\n",
       "          (Wg): Linear(in_features=144, out_features=5, bias=True)\n",
       "          (Wnoise): Linear(in_features=144, out_features=5, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (12): MoETransformerEncoderLayer(\n",
       "      (norm1): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GroupedQueryAttention(\n",
       "        (q_proj): Linear(in_features=144, out_features=144, bias=True)\n",
       "        (k_proj): Linear(in_features=144, out_features=72, bias=True)\n",
       "        (v_proj): Linear(in_features=144, out_features=72, bias=True)\n",
       "        (out_proj): Linear(in_features=144, out_features=144, bias=True)\n",
       "        (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (proj_dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (norm2): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
       "      (moe): MoELayer(\n",
       "        (experts): ModuleList(\n",
       "          (0-4): 5 x SwiGLU(\n",
       "            (W): Linear(in_features=144, out_features=82, bias=True)\n",
       "            (V): Linear(in_features=144, out_features=82, bias=True)\n",
       "            (W2): Linear(in_features=82, out_features=144, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (gate): NoisyTopKGate(\n",
       "          (Wg): Linear(in_features=144, out_features=5, bias=True)\n",
       "          (Wnoise): Linear(in_features=144, out_features=5, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (13): MoETransformerEncoderLayer(\n",
       "      (norm1): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GroupedQueryAttention(\n",
       "        (q_proj): Linear(in_features=144, out_features=144, bias=True)\n",
       "        (k_proj): Linear(in_features=144, out_features=72, bias=True)\n",
       "        (v_proj): Linear(in_features=144, out_features=72, bias=True)\n",
       "        (out_proj): Linear(in_features=144, out_features=144, bias=True)\n",
       "        (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (proj_dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (norm2): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
       "      (moe): MoELayer(\n",
       "        (experts): ModuleList(\n",
       "          (0-4): 5 x SwiGLU(\n",
       "            (W): Linear(in_features=144, out_features=77, bias=True)\n",
       "            (V): Linear(in_features=144, out_features=77, bias=True)\n",
       "            (W2): Linear(in_features=77, out_features=144, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (gate): NoisyTopKGate(\n",
       "          (Wg): Linear(in_features=144, out_features=5, bias=True)\n",
       "          (Wnoise): Linear(in_features=144, out_features=5, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (14): MoETransformerEncoderLayer(\n",
       "      (norm1): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GroupedQueryAttention(\n",
       "        (q_proj): Linear(in_features=144, out_features=144, bias=True)\n",
       "        (k_proj): Linear(in_features=144, out_features=72, bias=True)\n",
       "        (v_proj): Linear(in_features=144, out_features=72, bias=True)\n",
       "        (out_proj): Linear(in_features=144, out_features=144, bias=True)\n",
       "        (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (proj_dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (norm2): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
       "      (moe): MoELayer(\n",
       "        (experts): ModuleList(\n",
       "          (0-4): 5 x SwiGLU(\n",
       "            (W): Linear(in_features=144, out_features=72, bias=True)\n",
       "            (V): Linear(in_features=144, out_features=72, bias=True)\n",
       "            (W2): Linear(in_features=72, out_features=144, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (gate): NoisyTopKGate(\n",
       "          (Wg): Linear(in_features=144, out_features=5, bias=True)\n",
       "          (Wnoise): Linear(in_features=144, out_features=5, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_size = \"S\"\n",
    "img_size = 40\n",
    "patch_size = 4\n",
    "in_channels = 7\n",
    "checkpoint_path = \"./weights/moe_mae_bigearthnet_ls/pretrained_S_best.pth\"\n",
    "encoder = build_model(\n",
    "        size=model_size,\n",
    "        img_size=img_size,\n",
    "        patch_size=patch_size,\n",
    "        in_chans=in_channels,\n",
    "    )\n",
    "model = MOEMAE(encoder).to(device)\n",
    "model = load_model(model,checkpoint_path,device)\n",
    "encoder = model.encoder\n",
    "encoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4dd9a0e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total mmLiT Encoder parameters: 2,366,798\n",
      "Trainable mmLiT Encoder parameters: 2,366,798\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in encoder.parameters())\n",
    "trainable_params = sum(p.numel() for p in encoder.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Total mmLiT Encoder parameters: {total_params:,}\")\n",
    "print(f\"Trainable mmLiT Encoder parameters: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1910e399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total mmLiT parameters: 2,537,562\n",
      "Trainable mmLiT parameters: 2,537,562\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Total mmLiT parameters: {total_params:,}\")\n",
    "print(f\"Trainable mmLiT parameters: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5473069e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigearth_transforms = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize((40, 40)),\n",
    "            ToFloat(),\n",
    "            ZScoreNormalize(\n",
    "                BigEarthNetInfo.STATISTICS[\"mean\"],\n",
    "                BigEarthNetInfo.STATISTICS[\"std\"],\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "train_dataset = EuroSATDatasetLS(\n",
    "        root_dir = data_path,\n",
    "        split_file = data_txt_train,\n",
    "        transform=bigearth_transforms,\n",
    "        return_one_hot=True,\n",
    "        strict=False,\n",
    "    )\n",
    "train_dataloader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=64,\n",
    "        persistent_workers=False,\n",
    "        prefetch_factor=4,\n",
    "        num_workers=4,\n",
    "        shuffle=False,\n",
    "        pin_memory=True,\n",
    "        # sampler=train_sampler,\n",
    "    )\n",
    "val_dataset = EuroSATDatasetLS(\n",
    "        root_dir = data_path,\n",
    "        split_file = data_txt_val,\n",
    "        transform=bigearth_transforms,\n",
    "        return_one_hot=True,\n",
    "        strict=False,\n",
    "    )\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=64,\n",
    "        persistent_workers=False,\n",
    "        prefetch_factor=4,\n",
    "        num_workers=4,\n",
    "        shuffle=False,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "test_dataset = EuroSATDatasetLS(\n",
    "        root_dir = data_path,\n",
    "        split_file = data_txt_test,\n",
    "        transform=bigearth_transforms,\n",
    "        return_one_hot=True,\n",
    "        strict=False,\n",
    "    )\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=64,\n",
    "        persistent_workers=False,\n",
    "        prefetch_factor=4,\n",
    "        num_workers=4,\n",
    "        shuffle=False,\n",
    "        pin_memory=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57162fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "npz_path_train = f\"{save_path}/x_y_train_geomoemae_{model_size}_embed_pos_500epochs.npz\"\n",
    "npz_path_val = f\"{save_path}/x_y_val_geomoemae_{model_size}_embed_pos_500epochs.npz\"\n",
    "npz_path_test = f\"{save_path}/x_y_test_geomoemae_{model_size}_embed_pos_500epochs.npz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163c5cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing embeddings:   0%|          | 0/254 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing embeddings: 100%|██████████| 254/254 [01:17<00:00,  3.28it/s]\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = compute_geomoemae_embeddings(\n",
    "    encoder,\n",
    "    train_dataloader,\n",
    "    device,\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8391c1ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train shape:  (16200, 105, 144)\n",
      "Y train shape:  (16200, 10)\n"
     ]
    }
   ],
   "source": [
    "print (\"X train shape: \", x_train.shape)\n",
    "print (\"Y train shape: \", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01a87b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4242a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\n",
    "        npz_path_train,\n",
    "        x_train=x_train,\n",
    "        y_train=y_train.astype(np.int16),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb829c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "del x_train\n",
    "del y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda4c672",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing embeddings:   0%|          | 0/85 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing embeddings: 100%|██████████| 85/85 [00:23<00:00,  3.59it/s]\n"
     ]
    }
   ],
   "source": [
    "x_val, y_val = compute_geomoemae_embeddings(\n",
    "    encoder,\n",
    "    val_dataloader,\n",
    "    device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "720af1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_val.reshape(x_val.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2ba9ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\n",
    "        npz_path_val,\n",
    "        x_val=x_val,\n",
    "        y_val=y_val.astype(np.int16),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf1a7d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "del x_val\n",
    "del y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56d4501",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing embeddings:   0%|          | 0/85 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing embeddings: 100%|██████████| 85/85 [00:24<00:00,  3.50it/s]\n"
     ]
    }
   ],
   "source": [
    "x_test, y_test = compute_geomoemae_embeddings(\n",
    "    encoder,\n",
    "    test_dataloader,\n",
    "    device,\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "644e738e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = x_test.reshape(x_test.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e91c187c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\n",
    "        npz_path_test,\n",
    "        x_test=x_test,\n",
    "        y_test=y_test.astype(np.int16),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc398050",
   "metadata": {},
   "outputs": [],
   "source": [
    "del x_test\n",
    "del y_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
